# MaryaD_Portfolio.github.io
It is your commitment to the process that will determine your progress.


## About Me
My journey into data analysis began during my undergraduate studies in Economics, where I frequently found myself drawn to the analytical aspects of my coursework and projects. This curiosity deepened during my MPhil research, where I experienced firsthand the power of data in uncovering insights and shaping understanding. What started as an academic interest gradually evolved into a passion for research and data-driven storytelling. Although I briefly considered pursuing a PhD to continue this exploration, I realized that what I truly wanted was to engage with real-world data — particularly in the contexts of economics, business, and market analysis. This decision was driven by my desire to build practical experience and create impactful work that reflects current, real-time dynamics.

Throughout my academic and professional journey, I’ve had exposure to tools like R and SPSS, especially during my econometrics coursework, and worked extensively with Excel during my internship at Nestlé. However, recognizing the growing demand for versatile, market-ready skills, I took the initiative to strengthen my toolkit. I began learning Python, SQL, and Tableau through self-paced, online courses, appreciating the flexibility and real-world relevance they offered. Regular practice and project-building have since become part of my routine, allowing me to continuously improve and apply what I learn.

Outside of technical skills, I’ve cultivated a disciplined, self-motivated approach to work — shaped by a deep commitment to structured growth, focus, and consistency. Even when faced with complex or demanding projects, I’ve learned to stay persistent, treating each challenge as an opportunity to improve and push my capabilities further.

I’m deeply committed to building a meaningful career in data analysis, and I bring both seriousness of purpose and a genuine enthusiasm to contribute to this ever-evolving field. I love staying updated with technological advancements, especially in areas like AI, and I’m always excited to explore new frontiers in data, learning, and innovation. My strong communication skills, analytical mindset, and eagerness to learn position me well for roles that combine technical analysis with practical impact.
This portfolio reflects my growth so far and marks the beginning of a journey I’m eager to continue — as a student, a contributor, and a disciplined analyst ready to make a difference.

[View my CV](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Maryam_Rizwan_CV_2025.pdf).

## Table of Contents
- [About Me](#about-me)
### Excel
   - [Sales Data Visualization in Excel](#sales-data-visualization-in-excel)
### SQL
   - [E-commerce Analysis in SQL](#e-commerce-analysis-in-sql)
   - [Data Cleaning Project in SQL ](#data-cleaning-project-in-sql)
   - [Data Exploration in SQL](#data-exploration-in-sql)
   - [Business Analysis in SQL](#business-analysis-in-sql)
### Python
   - [US Labor Market Analysis](#us-labor-market-analysis)
   - [Data Correlation in Python](#data-correlation-in-python)    
### Tableau
   - [Data Visualization in Tableau](#data-visualization-in-tableau)    
### PowerBI
   - [Amazon Sales Analysis in PowerBI](#amazon-sales-analysis-in-powerbi)

### Background and Contact
  
- [Education](#education)
  
- [Certificatons](#certifications)
  
- [Contact](#contact)

## Data Quality & Risk Insights for Operational Safety and Visibility

### End-to-End Data Analysis & Deduplication Project

This project simulates real-world challenges faced by organizations operating large vehicle fleets, with a focus on data quality, deduplication, risk event detection, and operational visibility. It demonstrates a structured, business-oriented approach to identifying and mitigating risks across driver behavior, freight tracking, vehicle faults, and maintenance data.

### Project Structure

The project is divided into modular, realistic components reflecting different facets of operational data:

| Section                          | Description                                                                                           |
|-----------------------------------|-------------------------------------------------------------------------------------------------------|
| 1. Risk Events Analysis           | Detects and visualizes risky driving events, cleans duplicates/missing data, and generates simple risk scores for drivers. |
| 2. Freight Visibility             | Simulates asset location tracking, identifies data quality gaps, and visualizes geographic distribution of tracked assets. |
| 3. Risky Driver & Event Mapping   | Aggregates driver risk profiles and visualizes event locations using interactive maps.                |
| 4. Vehicle Faults Analysis        | Explores common vehicle fault patterns, estimates operational downtime, and applies a basic predictive model for duplicate detection. |
| 5. Maintenance Data Quality       | Identifies inconsistencies (e.g., negative odometer readings) and duplicates in vehicle maintenance records. |
| 6. Final Recommendations          | Provides actionable suggestions for improving data pipelines, risk detection, and deduplication processes. |

### Key Features & Techniques

- Data Cleaning: Systematic handling of missing values, duplicates, and inconsistent records  
- Exploratory Data Analysis (EDA): Summary statistics, visual insights, and distribution checks  
- Geospatial Visualizations: Interactive maps of risk events and freight locations  
- Risk Scoring: Simple but interpretable risk aggregation for drivers  
- Predictive Deduplication Prototype: Random Forest model to simulate duplicate detection  
- Business-Oriented Recommendations: Practical next steps to enhance data quality and operational safety  

### Tools & Libraries

- Python (Pandas, NumPy, Matplotlib, Seaborn, Folium, Scikit-learn)  
- Jupyter Notebooks for iterative analysis  
- Simulated datasets for realistic scenario building  

### Project Motivation

This project was designed as a self-initiated learning exercise to develop practical skills aligned with data quality, deduplication, and operational risk management roles. It reflects an understanding of how poor data quality, undetected duplicates, and inconsistent information can impact business outcomes such as safety, asset visibility, and operational efficiency.

### Future Enhancements

- Integrating SQL-based quality checks  
- Scaling deduplication models with more sophisticated ML techniques  
- Simulating real-time data pipelines and monitoring  
- Exploring production-ready deployment for data quality solutions  

### Notes

This project was developed with guidance from AI tools (e.g., ChatGPT) for structure and coding assistance, but all logic, interpretation, and business framing were designed and understood by the author. Some intentional AI-generated inconsistencies were identified and corrected during the process to ensure quality.

## Sales Data Visualization in Excel
Interactive Excel dashboard analyzing historical sales data to identify revenue trends, profit margins, seasonal patterns, and geographic performance.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Sales_Data_Visualization_in_Excel.xlsm)

### Key Highlights
- Analyzed sales quantity, revenue, COGS, and profit from Adventure Works dataset (2008)
- Identified top-performing months, weekdays vs. weekend trends, and quarterly fluctuations
- Enabled dynamic filtering by region and time with slicers
- Built with Excel PivotTables, charts, and VBA macros
  
**Tools & Technologies:** Excel, VBA (Macros), PivotTables, and Data Visualization

**Focus Areas:** Business Intelligence, Sales Performance Monitoring, Time-Series Analysis, and Executive Reporting

## E-commerce Analysis in SQL
SQL-based analysis of e-commerce customer and order data to uncover product trends, buying behavior, and regional performance.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/E-commerce_Analysis_in_SQL.sql)

### Key Highlights
 - Cleaned and joined multiple tables (orders, customers, products) using SQL queries
 - Identified top-selling products, high-value customers, and order frequency
 - Analyzed regional demand and seasonal purchasing trends
 - Used aggregate functions, filtering, grouping, and subqueries for deep insights

**Tools & Technologies:** SQL

**Focus Areas:** Customer behavior, product trends, order patterns, regional segmentation, e-commerce analytics

## Data Cleaning Project in SQL
SQL script for cleaning and preparing Nashville housing sales data, transforming raw data into a structured, analysis-ready dataset.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Data_Cleaning_Project_in_SQL.sql)

### Key Highlights
 - Standardized date formats (e.g., converting timestamps to clean date types)
 - Populated missing property addresses using COALESCE with self-joins on parcelid
 - Split addresses into address, city, and state columns for both property and owner fields
 - Converted flag values (e.g., "Y"/"N") into clear text ("Yes"/"No")
 - Identified and removed duplicates using window functions (e.g., ROW_NUMBER())
 - Dropped unnecessary columns after splitting address information

**Tools & Technologies:** SQL (T‑SQL/PostgreSQL), Data Cleaning, Window Functions, String Parsing

**Focus Areas:** Data Preparation, ETL, Data Quality, Clean Architecture, Housing Analytics

## Data Exploration in SQL
Interactive data analysis project exploring COVID‑19 cases, deaths, and vaccination trends to extract insights on pandemic progression and public health impact.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Data_Exploration_in_SQL.sql)

### Key Highlights
 - Processed comprehensive datasets on COVID‑19 cases, deaths, and vaccinations across countries/regions
 - Conducted time-series analysis to track infection waves, peak case periods, and mortality trends
 - Compared death vs. vaccination rates to assess immunization effects on outcomes
 - Visualized global and regional pandemic dynamics using charts in an interactive notebook

**Tools & Technologies:** Python (Pandas, Matplotlib/Seaborn), Jupyter Notebook, Data Visualization

**Focus Areas:** Epidemiological Trends, Public Health Analytics, Time-Series Analysis, Data-Driven Policy Insights

## Business Analysis in SQL
SQL script designed to clean, transform, and analyze sales transaction data, delivering actionable insights into revenue, product performance, and customer behavior.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Business_Analysis_in_SQL.sql)

### Key Highlights
 - Cleaned and standardized sales transaction records (dates, product IDs, order values)
 - Calculated key metrics including total revenue, units sold, and average order value per customer
 - Derived time-based aggregations (daily, monthly, quarterly sales trends) using date functions and GROUP BY
 - Classified products into categories/subcategories via CASE statements for better insights
 - Ranked top-performing products and customers using window functions (e.g., ROW_NUMBER(), RANK())
 - Joined sales with customer and product tables to create enriched analytics-ready tables

**Tools & Technologies:** SQL 

**Focus Areas:** Sales Analytics, Revenue Tracking, Customer Segmentation, Time-Series Analysis

## US Labor Market Analysis 
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/US_Labor_Market_Analysis.ipynb)

Interactive Jupyter Notebook analyzing key indicators of the U.S. labor market to uncover trends in employment, unemployment, and sectoral performance.

### Key Highlights
 - Scraped and processed datasets on employment, unemployment rate, and labor force participation over time
 - Conducted time-series analysis highlighting trends, recessions, and COVID‑19 labor disruptions
 - Performed sectoral breakdown by industry to identify job growth and decline across categories
 - Explored demographic impacts on labor participation, including gender and age group analysis
 - Visualized trends and comparisons using line plots, bar charts, and heatmaps in an interactive notebook

**Tools & Technologies:** Python (Pandas, Matplotlib, Seaborn), Jupyter Notebook, Time-Series Analysis

**Focus Areas:** Labor Market Analytics, Employment Trends, Sectoral Analysis, Demographic Study


## Data Correlation in Python
Interactive Jupyter Notebook exploring key trends and performance in the Hollywood film industry through box office, genre, and rating data.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Data_Correlation_in_Python.ipynb)

### Key Highlights
 - Collected and cleaned datasets on box office revenues, IMDb/Rotten Tomatoes ratings, and film genres
 - Analyzed time-series trends in yearly movie production and revenue growth
 - Conducted genre performance comparison, identifying top-earning and best-rated categories
 - Examined rating vs. revenue correlation to assess the impact of critical acclaim on financial success
 - Highlighted top-performing films by revenue and reputation using interactive charts

**Tools & Technologies:** Python (Pandas, Matplotlib, Seaborn), Jupyter Notebook, Exploratory Data Analysis

**Focus Areas:** Film Industry Insights, Box Office Analytics, Genre & Rating Analysis, Entertainment Data Storytelling

## Data Visualization in Tableau
Interactive Tableau dashboard visualizing COVID-19 trends worldwide to highlight case counts, death rates, geographic spread, and infection forecasting by country and continent.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Data_Visualization_in_Tableau.md)

### Key Highlights:
 - Summarized global totals of COVID-19 cases, deaths, and death percentages
 - Compared total deaths across continents to identify high-impact region
 - Analyzed infection trends over time, with actual vs. estimated % of population infected
 - Visualized country-level infection percentages on a choropleth map
 - Enabled multi-country and time-based comparisons using visual forecast lines and filters

**Tools and Technologies:** Tableau, Forecasting, Geographic Mapping

**Focus Areas:** Public health analytics, pandemic trend analysis, forecasting, data storytelling

## Amazon Sales Analysis in PowerBI
Interactive Power BI dashboard analyzing Amazon product sales to uncover key revenue drivers, customer engagement levels, and quarterly trends.
[View Code](https://github.com/Marya-D2307/MaryaD_Portfolio.github.io/blob/main/Amazon_Sales_Analysis_in_PowerBI.pbix)

### Key Highlights
 - Tracked YTD sales and QTD sales with KPIs for products sold and customer reviews
 - Visualized monthly and weekly sales patterns
 - Ranked top 5 product categories by YTD sales and reviews 
 - Enabled filtering by product category and quarter using slicers for deeper insights
 - Combined bar charts, line graphs, and interactive tables for executive-level reporting

**Tools & Technologies:** Power BI, DAX, Interactive Visuals, Data Modeling

**Focus Areas:** Business Intelligence, E-commerce Analytics, Sales Trend Analysis, Data-Driven Decision Making

## Education

### MPhil. in Economics,University of the Punjab, Lahore | 2019 - 2021
 - 3rd Position, Batch of 2021 | CGPA: 3.39
 - Thesis Topic: 'Gig Economy': An Alternative for Pakistani Female Labor Force Facing Structural Constraints
   
### BS (Honors) in Economics, Lahore College for Women University | 2015-2019
 - 1st Position, Batch of 2019 | CGPA: 3.79
 - Awarded Academic Roll of Honor

## Certifications

### Coursera
 - Google Data Analytics Professional Certificate | Nov/2021 - Jan/2022
 - Programming for Everybody (Getting Started with Python) | Jun/2024
 - Strategic Business Analytics Specialization | Jul/2024 - Aug/2024

### Cactus University
 - Editing Basics | April/2022 - May/2022
 - Introductory Course for LBL ROCs (SES) | May/2022 - Jun/2022

## Contact

 -  Email: maryamrizwan7@gmail.com ; marya.d0723@gmail.com  
 -  LinkedIn: [@maryamrizwan](https://linkedin.com/in/yourprofile)

